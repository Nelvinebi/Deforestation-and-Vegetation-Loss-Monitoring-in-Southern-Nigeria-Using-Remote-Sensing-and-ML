import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.preprocessing import StandardScaler

# -----------------------------
# 1. Generate Synthetic Dataset
# -----------------------------

np.random.seed(42)
n_samples = 3000

data = pd.DataFrame({
    "red_band": np.random.uniform(0.05, 0.4, n_samples),
    "nir_band": np.random.uniform(0.2, 0.8, n_samples),
    "lst": np.random.normal(305, 5, n_samples),          # Kelvin
    "rainfall": np.random.normal(1800, 300, n_samples),  # mm/year
    "elevation": np.random.uniform(0, 500, n_samples),   # meters
    "soil_moisture": np.random.uniform(0.1, 0.5, n_samples)
})

# -----------------------------
# 2. Vegetation Indices
# -----------------------------

data["ndvi"] = (data["nir_band"] - data["red_band"]) / \
               (data["nir_band"] + data["red_band"])

data["evi"] = 2.5 * (data["nir_band"] - data["red_band"]) / \
              (data["nir_band"] + 6 * data["red_band"] + 1)

data["nbr"] = (data["nir_band"] - data["lst"]/350) / \
              (data["nir_band"] + data["lst"]/350)

# -----------------------------
# 3. Simulate Deforestation Label
# -----------------------------

deforestation_score = (
    -2.5 * data["ndvi"] +
    0.04 * (data["lst"] - 300) -
    0.0004 * data["rainfall"] +
    0.002 * data["elevation"] +
    np.random.normal(0, 0.4, n_samples)
)

data["deforestation"] = (deforestation_score > np.percentile(deforestation_score, 65)).astype(int)

# -----------------------------
# 4. Feature Selection
# -----------------------------

features = [
    "ndvi", "evi", "nbr", "lst",
    "rainfall", "soil_moisture", "elevation"
]

X = data[features]
y = data["deforestation"]

# -----------------------------
# 5. Train/Test Split
# -----------------------------

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.25, stratify=y, random_state=42
)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# -----------------------------
# 6. Machine Learning Model
# -----------------------------

model = RandomForestClassifier(
    n_estimators=300,
    max_depth=12,
    random_state=42,
    class_weight="balanced"
)

model.fit(X_train, y_train)

# -----------------------------
# 7. Evaluation
# -----------------------------

y_pred = model.predict(X_test)

print("\nClassification Report:\n")
print(classification_report(y_test, y_pred))

print("\nConfusion Matrix:\n")
print(confusion_matrix(y_test, y_pred))

# -----------------------------
# 8. Feature Importance
# -----------------------------

importances = model.feature_importances_
importance_df = pd.DataFrame({
    "Feature": features,
    "Importance": importances
}).sort_values(by="Importance", ascending=False)

plt.figure(figsize=(8, 5))
plt.barh(importance_df["Feature"], importance_df["Importance"])
plt.xlabel("Importance")
plt.title("Feature Importance for Deforestation Detection")
plt.gca().invert_yaxis()
plt.show()
